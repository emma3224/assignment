{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjqUnt3y5WXA"
      },
      "source": [
        "# Assessment 2 - Data Preparation Tasks\n",
        "\n",
        "## Emma Waterman, Student ID # S00415342"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9iAxk53FbRa"
      },
      "source": [
        "## Task 1\n",
        "\n",
        "**Instructions**\n",
        "\n",
        "Good structure of Python Jupyter Notebook.\n",
        "\n",
        "Containing title cells, subtitle cells.\n",
        "Python codes are reasonably separated into groups (code cells) with functionalities.\n",
        "Containing meaningful comments and sensible variable and function names.\n",
        "Make sure to:\n",
        "\n",
        "Use the text cell in Google Colab to explain your code and interpret the outputs. Your explanation of the code and interpretation of the outputs is as important as the code itself.\n",
        "Use different level of headings to make the hierarchy of your submission clear."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qcVz3PEFbRa"
      },
      "source": [
        "**prepare for task 2**\n",
        "\n",
        "download URL file, save as txt file and open in Excel.\n",
        "\n",
        "Select all column headers, select 'Format Cells' and select date format - DD-Month(abbreviated)-Year.\n",
        "\n",
        "Save excel file as .CSV."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5zoINa6tFlV7",
        "outputId": "4d737307-4924-4e3d-c892-01f4b173c61b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHRks9GAFbRa"
      },
      "source": [
        "## Task 2\n",
        "\n",
        "**Instructions**\n",
        "\n",
        "Download csv data with pandas with below code:\n",
        "\n",
        "import pandas as pd\n",
        "deaths_df=pd.read_csv: 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv'Links to an external site.\n",
        "\n",
        "\n",
        "\n",
        "Note: You may find you have already been provided with the solution for Task 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "scrolled": true,
        "id": "_cpKV-ZxFbRb",
        "outputId": "f9169c73-68f3-490b-b509-c0ff6b3209fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'deaths_global_covid19copy101.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-865068080>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'deaths_global_covid19copy101.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#read csv file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;31m#reads whole file as pandas dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'deaths_global_covid19copy101.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from pandas import Series, DataFrame\n",
        "\n",
        "data = pd.read_csv('deaths_global_covid19copy101.csv') #read csv file\n",
        "data #reads whole file as pandas dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkwWyspuFbRb"
      },
      "source": [
        "## Task 3\n",
        "\n",
        "**Instructions**\n",
        "\n",
        "Display the first five rows of the loaded data (2 marks) and do a short summary of the data (3 marks).\n",
        "\n",
        "Note: There is a function that can create some descriptive statistics, what is that function? When you attempt this, you may also want to consider whether the statistics you create make sense, e.g. does it make sense to calculate the average of longitudes of countries/provinces/states in this dataset?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zsW2xnDZFbRb",
        "outputId": "67fb3ff0-04dd-420b-a627-ef5024c61891",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'deaths_global_covid19copy101.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-1053382923>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'deaths_global_covid19copy101.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#read csv file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#slices dataframe to equal first 5 rows. Remember, index starting point = 0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'deaths_global_covid19copy101.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from pandas import Series, DataFrame\n",
        "\n",
        "\n",
        "data = pd.read_csv('deaths_global_covid19copy101.csv') #read csv file\n",
        "\n",
        "data.loc[:4] #slices dataframe to equal first 5 rows. Remember, index starting point = 0.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P26bsu2MFbRc"
      },
      "outputs": [],
      "source": [
        "data.describe() #provides descriptive statistics for whole csv file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0L9uLmD4FbRc"
      },
      "outputs": [],
      "source": [
        "grouped_data = data.groupby('Country/Region')[data.columns[50:60]].mean(1) #group data by 'Country/Region'\n",
        "# Calculate Mean of every column per country = Cumulative average deaths per date by country #sample size columns 50 through to 60.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "filtered_data = grouped_data.replace(0, np.nan) #replaces 0 with 'Not a Number' value\n",
        "\n",
        "def format_with_scale(val): #formatting function for values\n",
        "    if pd.isna(val):\n",
        "        return ' '  #returns blank if value = 0\n",
        "    elif abs(val) >= 1_000_000:\n",
        "        return f'{val/1_000_000:.1f}M'  # Millions #returns number of a million with suffix 'M'\n",
        "    elif abs(val) >= 1_000:\n",
        "        return f'{val/1_000:.1f}K'      # Thousands #returns number of a thousand with suffix 'k'\n",
        "    else:\n",
        "        return f'{val:.1f}'             # Regular numbers #No suffix attached, Round to 1 decimal place\n",
        "\n",
        "\n",
        "styled_df = filtered_data.style.set_caption(\"Average Covid-19 Deaths per Country/Region & Date\").set_table_styles([\n",
        "    {'selector': 'th', 'props': [('font-weight', 'bold')]},  #create title, medium font size, Bold fond.\n",
        "    {'selector': 'caption', 'props': [('font-weight', 'bold'), ('font-size', 'Medium')]}\n",
        "])\n",
        "\n",
        "styled_df = styled_df.format(formatter=format_with_scale) #formats table to include title style and scale, rounding to 1 decimal place\n",
        "\n",
        "styled_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzLJNharFbRc"
      },
      "source": [
        "## Task 4\n",
        "\n",
        "**Instructions**\n",
        "\n",
        "Get daily death cases worldwide.\n",
        "\n",
        "Note: We are after the cumulative worldwide confirmed cases (summarising daily death cases in overall countries). You should produce ONE series that lists the cumulative worldwide confirmed cases against date, i.e. the index is the date and the value is the cumulative worldwide confirmed cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "hisIHcToFbRc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from pandas import Series, DataFrame\n",
        "import numpy as np\n",
        "\n",
        "data = pd.read_csv('deaths_global_covid19copy101.csv')\n",
        "\n",
        "date_columns = data.columns[4:]\n",
        "\n",
        "cumulative_worldwide = data[date_columns].sum()\n",
        "\n",
        "cumulative_worldwide.index = pd.to_datetime(cumulative_worldwide.index,format= '%d-%b-%y')\n",
        "\n",
        "monthly = cumulative_worldwide.groupby(cumulative_worldwide.index.to_period('M')).sum()\n",
        "\n",
        "monthly.index = monthly.index.to_timestamp()\n",
        "\n",
        "def format_val(x):\n",
        "    if pd.isna(x): return ' '\n",
        "    elif x >= 1_000_000: return f'{x/1_000_000:.2f}M'\n",
        "    elif x >= 1_000: return f'{x/1_000:.2f}K'\n",
        "    return f'{x:.0f}'\n",
        "\n",
        "\n",
        "formatted_monthly = monthly.map(format_val)\n",
        "pd.set_option('display.max_rows', None)  # Show all rows\n",
        "\n",
        "formatted_monthly\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gohyH6xLFbRc"
      },
      "source": [
        "## Task 5\n",
        "\n",
        "**Instructions**\n",
        "\n",
        "Get daily increase of death cases via defining a function. Hint: Use the death cases of today minus the death cases of yesterday from the data obtained in Task 4.\n",
        "\n",
        "Note: This time you are calculating  the daily cases worldwide, that is, the NEW cases confirmed just on a specific day and NOT the cumulative number for each day."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "5PM97ph7FbRc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "data = pd.read_csv('deaths_global_covid19copy101.csv')\n",
        "\n",
        "def get_daily_death_increase(data):\n",
        "\n",
        "    date_cols = data.columns[4:]\n",
        "    global_total = data[date_cols].sum(axis=0)\n",
        "    daily_increase = global_total.diff().fillna(0).round(2)\n",
        "    return daily_increase\n",
        "\n",
        "daily_increase = get_daily_death_increase(data)\n",
        "\n",
        "percentage = daily_increase.pct_change()\n",
        "\n",
        "daily_difference_percentage_change = percentage.fillna(0).round(2).replace([np.inf, -np.inf], 0)\n",
        "\n",
        "daily_difference_percentage_change"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0wEIM1EFbRc"
      },
      "source": [
        "## Task 6\n",
        "\n",
        "**Instructions**\n",
        "\n",
        "Visualise the data obtained in Task 4 with library matplotlib.\n",
        "\n",
        "Choose a diagram/plot that makes sense. Please note that you need to plot the data in Task 4, NOT Task 5. Don’t forget about all the elements in a plot: Have you labelled your x-axis? How about y-axis? Legend?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "wtqfl1RuFbRd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "import matplotlib.path as path\n",
        "from matplotlib.ticker import FuncFormatter\n",
        "\n",
        "data = pd.read_csv('deaths_global_covid19copy101.csv')\n",
        "\n",
        "date_columns = data.columns[4:]\n",
        "worldwide = data[date_columns].sum()\n",
        "worldwide.index = pd.to_datetime(worldwide.index,format= '%d-%b-%y')\n",
        "\n",
        "def convert_str(x):\n",
        "    if isinstance(x, str):\n",
        "        x = x.upper().replace(',', '')\n",
        "        if 'M' in x:\n",
        "            return float(x.replace('M', '')) * 1_000_000\n",
        "        elif 'K' in x:\n",
        "            return float(x.replace('K', '')) * 1_000\n",
        "        else:\n",
        "            return float(x)\n",
        "    return x\n",
        "\n",
        "cumulative_worldwide = worldwide.apply(convert_str)\n",
        "\n",
        "cumulative_worldwide.index = pd.to_datetime(cumulative_worldwide.index)\n",
        "cumulative_worldwide = cumulative_worldwide.sort_index()\n",
        "\n",
        "quarterly_sum = cumulative_worldwide.resample('QE').sum()\n",
        "\n",
        "plt.figure(figsize=(16,10))\n",
        "\n",
        "plt.plot(quarterly_sum.index, quarterly_sum.values, marker='o',ms=10, linestyle='-')\n",
        "\n",
        "quarter_labels = (quarterly_sum.index - pd.offsets.QuarterEnd(startingMonth=3) + pd.offsets.QuarterBegin()).strftime('%b-%Y')\n",
        "\n",
        "plt.title('Worldwide Covid-19 Deaths Over Time (Quarterly)',fontsize=25.0, fontweight= 'bold', fontname='Century Schoolbook', pad=25)\n",
        "\n",
        "plt.xlabel('Yearly Quarters', fontsize=20, fontname='Century Schoolbook',labelpad=25)\n",
        "plt.ylabel('Number of Deaths',fontsize=20, fontname='Century Schoolbook', labelpad=25)\n",
        "\n",
        "plt.xticks(ticks=quarterly_sum.index, labels=quarter_labels, rotation=45, fontsize=12)\n",
        "\n",
        "\n",
        "ticks = np.arange(5_000_000, 100_000_001, 5_000_000)\n",
        "def millions_formatter(x, pos):\n",
        "    return f'{x/1_000_000:.0f}M'\n",
        "\n",
        "plt.gca().yaxis.set_major_formatter(FuncFormatter(millions_formatter))\n",
        "\n",
        "plt.style.use('seaborn-v0_8-pastel')\n",
        "plt.show()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}